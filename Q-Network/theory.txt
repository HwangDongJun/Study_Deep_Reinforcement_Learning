Q-Table이 색깔도 한가지며, 아주 간단한 크기의 table의 경우에만 적용이 가능하다.
만약 요즘 게임같은 경우에는 매우 많은 경우의 수가 존재하기 때문에 적용하기가 어렵다.
그래서 나온 개념이 Q-Network이다.

- 2가지 경우
1. 상태(state)와 액션(action)을 Network에 주고, 받을 수 있는 값 하나
2. 상태(state)만 Network에 주고, 받을 수 있는 모든 action 값
* 우리는 2번째 경우를 사용할 것이다.

(Q-Network_Training.PNG를 참고)
s는 상태를 network에 넣고, 중간을 W라고 했을경우 출력되는 예측값은 Ws이다.
그 추측값을 표시한게 Q_hat(s, a | θ) 이다.
그리고 Choose θ to minimize는 cost 함수를 구하는 과정을 표시한 것이다.
Q_hat(s, a | θ) - [이부분] -> 이 부분이 y(label)이다.